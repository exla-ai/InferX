---
title: 'Introduction to Exla'
description: 'Hardware-aware AI model optimization for edge devices'
---

# Welcome to Exla

Exla is an advanced model optimization platform that makes AI models smaller, faster, and more deployable on constrained devices. We provide hardware-aware model optimization, enabling developers to deploy efficient, production-ready models with just a few lines of code.

## Key Features

- **Hardware-Aware Optimization**: Automatically optimizes models based on target hardware specifications
- **Mixed Precision Quantization**: Adaptive bit-width precision for optimal performance
- **Structured Pruning**: Intelligent removal of redundant computations while preserving accuracy
- **Kernel Fusion**: Advanced optimizations for reduced memory overhead and improved inference speed
- **Simple Integration**: Deploy optimized models with minimal configuration
- **Multiple Hardware Support**: Optimized for various GPUs and edge devices

## Why Exla?

Optimizing models for edge devices like NVIDIA Jetsons and Raspberry Pis is notoriously complex and time-consuming. Exla automates this process, making it possible to run large models on low-power hardware without sacrificing performance.

## Getting Started

To start using Exla in your project, check out our [Quickstart Guide](/quickstart) or explore our [Hardware & Model Compatibility](/compatibility).

## Connect With Us

- Email: contact@exla.ai
- Twitter: [@exla_ai](https://x.com/exla_ai)
- LinkedIn: [Exla](https://linkedin.com/company/106019408) 