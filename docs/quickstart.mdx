---
title: 'Quickstart'
description: 'Get started with Exla SDK in minutes'
---

# Setup Guide

This guide will walk you through setting up your environment for using the Exla SDK. We'll cover installing the necessary tools, creating a virtual environment, and installing the SDK.

## Prerequisites

Before you begin, make sure you have:

- Python 3.10 or later installed
- Git installed
- Access to the Exla SDK repository (you'll need an access token)

## Step 1: Set up docker in sudo mode

```bash
sudo usermod -aG docker $USER
```

## Step 2: Install uv

First, install `uv`, a fast Python package installer and resolver that we recommend for managing dependencies:

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

This will install `uv` on your system. After installation, you may need to restart your terminal or source your shell configuration file to use `uv`.

## Step 3: Create a Project Directory

Create a new directory for your project and navigate into it:

```bash
mkdir exla-project && cd exla-project
```

## Step 4: Create a Virtual Environment

Create a Python virtual environment using `uv`. We recommend using Python 3.10 for optimal compatibility:

```bash
uv venv --python 3.10
```

This creates a virtual environment in the `.venv` directory. Activate the virtual environment:

```bash
# On Linux/macOS
source .venv/bin/activate

# On Windows
.venv\Scripts\activate
```

## Step 5: Set the GitHub Token

Set the GitHub token as an environment variable:

```bash
export EXLA_TOKEN=ghp_xxxxxx # Replace with token provided by Exla team
```

## Step 6: Install the Exla SDK

Install the Exla SDK directly from the GitHub repository using your access token:

```bash
uv pip install git+https://${EXLA_TOKEN}@github.com/exla-ai/exla-sdk.git
```

If everything is set up correctly, you should see the Exla SDK version and a success message!


## Next Steps

Now that you have set up your environment and tested the Exla SDK, you can:

- Explore the [Quickstart Guide](/quickstart) for more examples
- Check out the [CLIP model documentation](/models/clip) for image-text matching
- Try the [RoboPoint model](/models/robopoint) for keypoint affordance prediction
- Learn about [hardware compatibility](/compatibility) for optimized performance

## Troubleshooting

If you encounter any issues during setup:

- Make sure you're using Python 3.10 or later
- Verify that your access token has the necessary permissions
- Check that all dependencies are properly installed
- Please don't hesitate to reach out to us on email at [contact@exla.ai](mailto:contact@exla.ai)
